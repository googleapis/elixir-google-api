# Copyright 2019 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# NOTE: This file is auto generated by the elixir code generator program.
# Do not edit this file manually.

defmodule GoogleApi.Dataproc.V1.Model.Batch do
  @moduledoc """
  A representation of a batch workload in the service.

  ## Attributes

  *   `createTime` (*type:* `DateTime.t`, *default:* `nil`) - Output only. The time when the batch was created.
  *   `creator` (*type:* `String.t`, *default:* `nil`) - Output only. The email address of the user who created the batch.
  *   `environmentConfig` (*type:* `GoogleApi.Dataproc.V1.Model.EnvironmentConfig.t`, *default:* `nil`) - Optional. Environment configuration for the batch execution.
  *   `labels` (*type:* `map()`, *default:* `nil`) - Optional. The labels to associate with this batch. Label keys must contain 1 to 63 characters, and must conform to RFC 1035 (https://www.ietf.org/rfc/rfc1035.txt). Label values may be empty, but, if present, must contain 1 to 63 characters, and must conform to RFC 1035 (https://www.ietf.org/rfc/rfc1035.txt). No more than 32 labels can be associated with a batch.
  *   `name` (*type:* `String.t`, *default:* `nil`) - Output only. The resource name of the batch.
  *   `operation` (*type:* `String.t`, *default:* `nil`) - Output only. The resource name of the operation associated with this batch.
  *   `pysparkBatch` (*type:* `GoogleApi.Dataproc.V1.Model.PySparkBatch.t`, *default:* `nil`) - Optional. PySpark batch config.
  *   `runtimeConfig` (*type:* `GoogleApi.Dataproc.V1.Model.RuntimeConfig.t`, *default:* `nil`) - Optional. Runtime configuration for the batch execution.
  *   `runtimeInfo` (*type:* `GoogleApi.Dataproc.V1.Model.RuntimeInfo.t`, *default:* `nil`) - Output only. Runtime information about batch execution.
  *   `sparkBatch` (*type:* `GoogleApi.Dataproc.V1.Model.SparkBatch.t`, *default:* `nil`) - Optional. Spark batch config.
  *   `sparkRBatch` (*type:* `GoogleApi.Dataproc.V1.Model.SparkRBatch.t`, *default:* `nil`) - Optional. SparkR batch config.
  *   `sparkSqlBatch` (*type:* `GoogleApi.Dataproc.V1.Model.SparkSqlBatch.t`, *default:* `nil`) - Optional. SparkSql batch config.
  *   `state` (*type:* `String.t`, *default:* `nil`) - Output only. The state of the batch.
  *   `stateHistory` (*type:* `list(GoogleApi.Dataproc.V1.Model.StateHistory.t)`, *default:* `nil`) - Output only. Historical state information for the batch.
  *   `stateMessage` (*type:* `String.t`, *default:* `nil`) - Output only. Batch state details, such as a failure description if the state is FAILED.
  *   `stateTime` (*type:* `DateTime.t`, *default:* `nil`) - Output only. The time when the batch entered a current state.
  *   `uuid` (*type:* `String.t`, *default:* `nil`) - Output only. A batch UUID (Unique Universal Identifier). The service generates this value when it creates the batch.
  """

  use GoogleApi.Gax.ModelBase

  @type t :: %__MODULE__{
          :createTime => DateTime.t() | nil,
          :creator => String.t() | nil,
          :environmentConfig => GoogleApi.Dataproc.V1.Model.EnvironmentConfig.t() | nil,
          :labels => map() | nil,
          :name => String.t() | nil,
          :operation => String.t() | nil,
          :pysparkBatch => GoogleApi.Dataproc.V1.Model.PySparkBatch.t() | nil,
          :runtimeConfig => GoogleApi.Dataproc.V1.Model.RuntimeConfig.t() | nil,
          :runtimeInfo => GoogleApi.Dataproc.V1.Model.RuntimeInfo.t() | nil,
          :sparkBatch => GoogleApi.Dataproc.V1.Model.SparkBatch.t() | nil,
          :sparkRBatch => GoogleApi.Dataproc.V1.Model.SparkRBatch.t() | nil,
          :sparkSqlBatch => GoogleApi.Dataproc.V1.Model.SparkSqlBatch.t() | nil,
          :state => String.t() | nil,
          :stateHistory => list(GoogleApi.Dataproc.V1.Model.StateHistory.t()) | nil,
          :stateMessage => String.t() | nil,
          :stateTime => DateTime.t() | nil,
          :uuid => String.t() | nil
        }

  field(:createTime, as: DateTime)
  field(:creator)
  field(:environmentConfig, as: GoogleApi.Dataproc.V1.Model.EnvironmentConfig)
  field(:labels, type: :map)
  field(:name)
  field(:operation)
  field(:pysparkBatch, as: GoogleApi.Dataproc.V1.Model.PySparkBatch)
  field(:runtimeConfig, as: GoogleApi.Dataproc.V1.Model.RuntimeConfig)
  field(:runtimeInfo, as: GoogleApi.Dataproc.V1.Model.RuntimeInfo)
  field(:sparkBatch, as: GoogleApi.Dataproc.V1.Model.SparkBatch)
  field(:sparkRBatch, as: GoogleApi.Dataproc.V1.Model.SparkRBatch)
  field(:sparkSqlBatch, as: GoogleApi.Dataproc.V1.Model.SparkSqlBatch)
  field(:state)
  field(:stateHistory, as: GoogleApi.Dataproc.V1.Model.StateHistory, type: :list)
  field(:stateMessage)
  field(:stateTime, as: DateTime)
  field(:uuid)
end

defimpl Poison.Decoder, for: GoogleApi.Dataproc.V1.Model.Batch do
  def decode(value, options) do
    GoogleApi.Dataproc.V1.Model.Batch.decode(value, options)
  end
end

defimpl Poison.Encoder, for: GoogleApi.Dataproc.V1.Model.Batch do
  def encode(value, options) do
    GoogleApi.Gax.ModelBase.encode(value, options)
  end
end
